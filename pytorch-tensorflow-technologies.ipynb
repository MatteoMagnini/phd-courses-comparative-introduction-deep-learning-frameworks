{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PhD course: a Comparative Introduction to Deep Learning Frameworks: TensorFlow, PyTorch and JAX - Coursework\n",
    "@author Matteo Magnini, Ph.D. student of the Computer Science and Engineering (38th cycle) course of the University of Bologna.\n",
    "\n",
    "This notebook presents a comparison study between `pytorch` and `tensorflow`.\n",
    "Given a public dataset, the same ML model -- a deep neural network -- is build, trained and tested with both technologies.\n",
    "Moreover, the two models are also evaluated on the computational time during training.\n",
    "\n",
    "Note: the experiments are reproducible via explicit seed declaration (just change it if you want to see different executions)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some necessary imports."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyper-parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATASET_URL = 'http://lib.stat.cmu.edu/datasets/houses.zip'\n",
    "\n",
    "SEED = 1\n",
    "TRAIN_RATIO = 2 / 3\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "NEURONS = [128, 128, 64, 64, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)\n",
    "\n",
    "\n",
    "def create_pytorch_net(input_shape, neurons):\n",
    "    linear_layers = [nn.Linear(neurons[i], neurons[i + 1])for i in range(len(neurons) - 1)]\n",
    "    relu_layers = (len(neurons) - 1) * [nn.ReLU()]\n",
    "    mixed_layers = [None]*(len(linear_layers)+len(relu_layers))\n",
    "    mixed_layers[::2] = relu_layers\n",
    "    mixed_layers[1::2] = linear_layers\n",
    "    return nn.Sequential(nn.Linear(input_shape, neurons[0]), *mixed_layers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset\n",
    "The dataset I use for this coursework contains the housing prices of California in 1990.\n",
    "It is public available at `http://lib.stat.cmu.edu/datasets/houses.zip`.\n",
    "\n",
    "A brief description from authors:\n",
    "> We collected information on the variables using all the block groups in California from the 1990 Census.\n",
    "In this sample a block group on average includes 1425.5 individuals living in a geographically compact area.\n",
    "Naturally, the geographical area included varies inversely with the population density.\n",
    "We computed distances among the centroids of each block group as measured in latitude and longitude.\n",
    "We excluded all the block groups reporting zero entries for the independent and dependent variables.\n",
    "The final data contained 20,640 observations on 9 variables.\n",
    "The dependent variable is ln(median house value).\n",
    "\n",
    "The dataset consists of 8 independent variables and 1 dependent variable (median house value).\n",
    "The dataset contains 20,640 records.\n",
    "The task is to predict the house cost value from the independent variable (regression)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       median_house_value  median_income  housing_median_age         rooms  \\\ncount        20640.000000   20640.000000        20640.000000  20640.000000   \nmean        206855.816909       3.870671           28.639486   2635.763081   \nstd         115395.615874       1.899822           12.585558   2181.615252   \nmin          14999.000000       0.499900            1.000000      2.000000   \n25%         119600.000000       2.563400           18.000000   1447.750000   \n50%         179700.000000       3.534800           29.000000   2127.000000   \n75%         264725.000000       4.743250           37.000000   3148.000000   \nmax         500001.000000      15.000100           52.000000  39320.000000   \n\n           bedrooms    population    households      latitude     longitude  \ncount  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000  \nmean     537.898014   1425.476744    499.539680     35.631861   -119.569704  \nstd      421.247906   1132.462122    382.329753      2.135952      2.003532  \nmin        1.000000      3.000000      1.000000     32.540000   -124.350000  \n25%      295.000000    787.000000    280.000000     33.930000   -121.800000  \n50%      435.000000   1166.000000    409.000000     34.260000   -118.490000  \n75%      647.000000   1725.000000    605.000000     37.710000   -118.010000  \nmax     6445.000000  35682.000000   6082.000000     41.950000   -114.310000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>median_house_value</th>\n      <th>median_income</th>\n      <th>housing_median_age</th>\n      <th>rooms</th>\n      <th>bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>latitude</th>\n      <th>longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>206855.816909</td>\n      <td>3.870671</td>\n      <td>28.639486</td>\n      <td>2635.763081</td>\n      <td>537.898014</td>\n      <td>1425.476744</td>\n      <td>499.539680</td>\n      <td>35.631861</td>\n      <td>-119.569704</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>115395.615874</td>\n      <td>1.899822</td>\n      <td>12.585558</td>\n      <td>2181.615252</td>\n      <td>421.247906</td>\n      <td>1132.462122</td>\n      <td>382.329753</td>\n      <td>2.135952</td>\n      <td>2.003532</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>14999.000000</td>\n      <td>0.499900</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>32.540000</td>\n      <td>-124.350000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>119600.000000</td>\n      <td>2.563400</td>\n      <td>18.000000</td>\n      <td>1447.750000</td>\n      <td>295.000000</td>\n      <td>787.000000</td>\n      <td>280.000000</td>\n      <td>33.930000</td>\n      <td>-121.800000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>179700.000000</td>\n      <td>3.534800</td>\n      <td>29.000000</td>\n      <td>2127.000000</td>\n      <td>435.000000</td>\n      <td>1166.000000</td>\n      <td>409.000000</td>\n      <td>34.260000</td>\n      <td>-118.490000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>264725.000000</td>\n      <td>4.743250</td>\n      <td>37.000000</td>\n      <td>3148.000000</td>\n      <td>647.000000</td>\n      <td>1725.000000</td>\n      <td>605.000000</td>\n      <td>37.710000</td>\n      <td>-118.010000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>500001.000000</td>\n      <td>15.000100</td>\n      <td>52.000000</td>\n      <td>39320.000000</td>\n      <td>6445.000000</td>\n      <td>35682.000000</td>\n      <td>6082.000000</td>\n      <td>41.950000</td>\n      <td>-114.310000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATASET_URL, sep=\"\\s+\", skiprows=27, header=None, encoding='windows-1252')\n",
    "data.columns = [\"median_house_value\", \"median_income\", \"housing_median_age\", \"rooms\", \"bedrooms\", \"population\", \"households\", \"latitude\", \"longitude\"]\n",
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split into train and test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       median_house_value  median_income  housing_median_age   rooms  \\\n16054            336100.0         4.4094                52.0  3260.0   \n20161            161200.0         2.5441                41.0  1408.0   \n6525             176100.0         3.2132                39.0  1258.0   \n15763            412500.0         2.3977                52.0  2514.0   \n19798             61500.0         1.8696                23.0  1091.0   \n...                   ...            ...                 ...     ...   \n10955            205300.0         1.7823                17.0  1768.0   \n17289            500001.0         8.5608                42.0  1765.0   \n5192             104800.0         1.1326                42.0  1433.0   \n12172            140700.0         2.6322                10.0  2381.0   \n235              126000.0         2.3036                35.0  1802.0   \n\n       bedrooms  population  households  latitude  longitude  \n16054     653.0      1594.0       632.0     37.76    -122.48  \n20161     311.0       793.0       264.0     34.37    -119.29  \n6525      245.0       988.0       228.0     34.06    -118.04  \n15763     729.0      1428.0       597.0     37.77    -122.43  \n19798     217.0       539.0       201.0     40.54    -123.12  \n...         ...         ...         ...       ...        ...  \n10955     474.0      1079.0       436.0     33.76    -117.88  \n17289     263.0       753.0       260.0     34.42    -119.63  \n5192      295.0       775.0       293.0     33.93    -118.26  \n12172     454.0      1323.0       477.0     33.73    -117.16  \n235       459.0      1009.0       390.0     37.79    -122.20  \n\n[13760 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>median_house_value</th>\n      <th>median_income</th>\n      <th>housing_median_age</th>\n      <th>rooms</th>\n      <th>bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>latitude</th>\n      <th>longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16054</th>\n      <td>336100.0</td>\n      <td>4.4094</td>\n      <td>52.0</td>\n      <td>3260.0</td>\n      <td>653.0</td>\n      <td>1594.0</td>\n      <td>632.0</td>\n      <td>37.76</td>\n      <td>-122.48</td>\n    </tr>\n    <tr>\n      <th>20161</th>\n      <td>161200.0</td>\n      <td>2.5441</td>\n      <td>41.0</td>\n      <td>1408.0</td>\n      <td>311.0</td>\n      <td>793.0</td>\n      <td>264.0</td>\n      <td>34.37</td>\n      <td>-119.29</td>\n    </tr>\n    <tr>\n      <th>6525</th>\n      <td>176100.0</td>\n      <td>3.2132</td>\n      <td>39.0</td>\n      <td>1258.0</td>\n      <td>245.0</td>\n      <td>988.0</td>\n      <td>228.0</td>\n      <td>34.06</td>\n      <td>-118.04</td>\n    </tr>\n    <tr>\n      <th>15763</th>\n      <td>412500.0</td>\n      <td>2.3977</td>\n      <td>52.0</td>\n      <td>2514.0</td>\n      <td>729.0</td>\n      <td>1428.0</td>\n      <td>597.0</td>\n      <td>37.77</td>\n      <td>-122.43</td>\n    </tr>\n    <tr>\n      <th>19798</th>\n      <td>61500.0</td>\n      <td>1.8696</td>\n      <td>23.0</td>\n      <td>1091.0</td>\n      <td>217.0</td>\n      <td>539.0</td>\n      <td>201.0</td>\n      <td>40.54</td>\n      <td>-123.12</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10955</th>\n      <td>205300.0</td>\n      <td>1.7823</td>\n      <td>17.0</td>\n      <td>1768.0</td>\n      <td>474.0</td>\n      <td>1079.0</td>\n      <td>436.0</td>\n      <td>33.76</td>\n      <td>-117.88</td>\n    </tr>\n    <tr>\n      <th>17289</th>\n      <td>500001.0</td>\n      <td>8.5608</td>\n      <td>42.0</td>\n      <td>1765.0</td>\n      <td>263.0</td>\n      <td>753.0</td>\n      <td>260.0</td>\n      <td>34.42</td>\n      <td>-119.63</td>\n    </tr>\n    <tr>\n      <th>5192</th>\n      <td>104800.0</td>\n      <td>1.1326</td>\n      <td>42.0</td>\n      <td>1433.0</td>\n      <td>295.0</td>\n      <td>775.0</td>\n      <td>293.0</td>\n      <td>33.93</td>\n      <td>-118.26</td>\n    </tr>\n    <tr>\n      <th>12172</th>\n      <td>140700.0</td>\n      <td>2.6322</td>\n      <td>10.0</td>\n      <td>2381.0</td>\n      <td>454.0</td>\n      <td>1323.0</td>\n      <td>477.0</td>\n      <td>33.73</td>\n      <td>-117.16</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>126000.0</td>\n      <td>2.3036</td>\n      <td>35.0</td>\n      <td>1802.0</td>\n      <td>459.0</td>\n      <td>1009.0</td>\n      <td>390.0</td>\n      <td>37.79</td>\n      <td>-122.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>13760 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(data, train_size=TRAIN_RATIO, random_state=SEED)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       median_house_value  median_income  housing_median_age     rooms  \\\n16054            0.662061       0.269617            1.000000  0.082863   \n20161            0.301444       0.140977            0.784314  0.035760   \n6525             0.332166       0.187122            0.745098  0.031945   \n15763            0.819586       0.130881            1.000000  0.063889   \n19798            0.095878       0.094461            0.431373  0.027697   \n...                   ...            ...                 ...       ...   \n10955            0.392372       0.088440            0.313725  0.044916   \n17289            1.000000       0.555916            0.803922  0.044840   \n5192             0.185156       0.043634            0.803922  0.036396   \n12172            0.259176       0.147053            0.176471  0.060507   \n235              0.228867       0.124391            0.666667  0.045781   \n\n       bedrooms  population  households  latitude  longitude  \n16054  0.105009    0.044592    0.117790  0.554729   0.182182  \n20161  0.049928    0.022142    0.049095  0.194474   0.501502  \n6525   0.039298    0.027607    0.042374  0.161530   0.626627  \n15763  0.117249    0.039939    0.111256  0.555792   0.187187  \n19798  0.034788    0.015023    0.037334  0.850159   0.118118  \n...         ...         ...         ...       ...        ...  \n10955  0.076180    0.030158    0.081202  0.129649   0.642643  \n17289  0.042197    0.021021    0.048348  0.199787   0.467467  \n5192   0.047351    0.021637    0.054508  0.147715   0.604605  \n12172  0.072959    0.036997    0.088856  0.126461   0.714715  \n235    0.073764    0.028196    0.072615  0.557917   0.210210  \n\n[13760 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>median_house_value</th>\n      <th>median_income</th>\n      <th>housing_median_age</th>\n      <th>rooms</th>\n      <th>bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>latitude</th>\n      <th>longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16054</th>\n      <td>0.662061</td>\n      <td>0.269617</td>\n      <td>1.000000</td>\n      <td>0.082863</td>\n      <td>0.105009</td>\n      <td>0.044592</td>\n      <td>0.117790</td>\n      <td>0.554729</td>\n      <td>0.182182</td>\n    </tr>\n    <tr>\n      <th>20161</th>\n      <td>0.301444</td>\n      <td>0.140977</td>\n      <td>0.784314</td>\n      <td>0.035760</td>\n      <td>0.049928</td>\n      <td>0.022142</td>\n      <td>0.049095</td>\n      <td>0.194474</td>\n      <td>0.501502</td>\n    </tr>\n    <tr>\n      <th>6525</th>\n      <td>0.332166</td>\n      <td>0.187122</td>\n      <td>0.745098</td>\n      <td>0.031945</td>\n      <td>0.039298</td>\n      <td>0.027607</td>\n      <td>0.042374</td>\n      <td>0.161530</td>\n      <td>0.626627</td>\n    </tr>\n    <tr>\n      <th>15763</th>\n      <td>0.819586</td>\n      <td>0.130881</td>\n      <td>1.000000</td>\n      <td>0.063889</td>\n      <td>0.117249</td>\n      <td>0.039939</td>\n      <td>0.111256</td>\n      <td>0.555792</td>\n      <td>0.187187</td>\n    </tr>\n    <tr>\n      <th>19798</th>\n      <td>0.095878</td>\n      <td>0.094461</td>\n      <td>0.431373</td>\n      <td>0.027697</td>\n      <td>0.034788</td>\n      <td>0.015023</td>\n      <td>0.037334</td>\n      <td>0.850159</td>\n      <td>0.118118</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10955</th>\n      <td>0.392372</td>\n      <td>0.088440</td>\n      <td>0.313725</td>\n      <td>0.044916</td>\n      <td>0.076180</td>\n      <td>0.030158</td>\n      <td>0.081202</td>\n      <td>0.129649</td>\n      <td>0.642643</td>\n    </tr>\n    <tr>\n      <th>17289</th>\n      <td>1.000000</td>\n      <td>0.555916</td>\n      <td>0.803922</td>\n      <td>0.044840</td>\n      <td>0.042197</td>\n      <td>0.021021</td>\n      <td>0.048348</td>\n      <td>0.199787</td>\n      <td>0.467467</td>\n    </tr>\n    <tr>\n      <th>5192</th>\n      <td>0.185156</td>\n      <td>0.043634</td>\n      <td>0.803922</td>\n      <td>0.036396</td>\n      <td>0.047351</td>\n      <td>0.021637</td>\n      <td>0.054508</td>\n      <td>0.147715</td>\n      <td>0.604605</td>\n    </tr>\n    <tr>\n      <th>12172</th>\n      <td>0.259176</td>\n      <td>0.147053</td>\n      <td>0.176471</td>\n      <td>0.060507</td>\n      <td>0.072959</td>\n      <td>0.036997</td>\n      <td>0.088856</td>\n      <td>0.126461</td>\n      <td>0.714715</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>0.228867</td>\n      <td>0.124391</td>\n      <td>0.666667</td>\n      <td>0.045781</td>\n      <td>0.073764</td>\n      <td>0.028196</td>\n      <td>0.072615</td>\n      <td>0.557917</td>\n      <td>0.210210</td>\n    </tr>\n  </tbody>\n</table>\n<p>13760 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = (train-train.min())/(train.max()-train.min()), (test-test.min())/(test.max()-test.min())\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PyTorch\n",
    "Dataframes are converted into pytorch tensors and then a `DataLoader` is created for both train and test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train = DataLoader(df_to_tensor(train), batch_size=BATCH_SIZE)\n",
    "test = DataLoader(df_to_tensor(test), batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definition of train and test loop functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train_loop(train_loader, model, loss_fn, opt):\n",
    "    \"\"\"\n",
    "    :param train_loader: pytorch loader for the training sry\n",
    "    :param model: the neural network\n",
    "    :param loss_fn: the loss function\n",
    "    :param opt: the optimizer\n",
    "    :return: the execution time (prints are excluded but the computations of loss and mae are included)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    num_batches = len(train_loader)\n",
    "    num_records = sum([batch.shape[0] for batch in train_loader])\n",
    "    train_loss, mae = 0, 0\n",
    "    for batch, train_batch in enumerate(train_loader):\n",
    "        train_x, train_y = train_batch[:, 1:], train_batch[:, :1]\n",
    "        pred_y = model(train_x)\n",
    "        loss = loss_fn(pred_y, train_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        train_loss /= num_batches\n",
    "        mae += sum(abs(train_y - pred_y))\n",
    "        opt.step()\n",
    "    loss, current = loss.item(), batch * len(train_x)\n",
    "    mae /= num_records\n",
    "    execution_time = time.time() - start_time\n",
    "    print(f\"loss: {loss:>4f}, mae: {mae.item(): > 0.4f}\")\n",
    "    return execution_time\n",
    "\n",
    "\n",
    "def test_loop(test_loader, model, loss_fn):\n",
    "    num_batches = len(test_loader)\n",
    "    num_records = sum([batch.shape[0] for batch in test_loader])\n",
    "    test_loss, mae, ssr, sst = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for test_batch in test_loader:\n",
    "            test_x, test_y = test_batch[:, 1:], test_batch[:, :1]\n",
    "            pred_y = model(test_x)\n",
    "            test_loss += loss_fn(pred_y, test_y).item() / num_batches\n",
    "            mae += sum(abs(test_y - pred_y))\n",
    "            ssr += sum((test_y - pred_y) ** 2)\n",
    "            sst += sum((test_y - test_loader.dataset[:, 0].mean()) ** 2)\n",
    "            r2 = (1 - ssr / sst).item()\n",
    "    rmse = (ssr / num_records) ** (1/2)\n",
    "    mae /= num_records\n",
    "    print(f\"\\nTest Error: loss: {test_loss: > 4f}, mae: {mae.item(): > 0.4f}, rmse: {rmse.item(): > 0.4f}, R2: {r2: > 0.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construction of the neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Linear(in_features=8, out_features=128, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=128, out_features=128, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=128, out_features=64, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=64, out_features=64, bias=True)\n  (7): ReLU()\n  (8): Linear(in_features=64, out_features=1, bias=True)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_seed(SEED)\n",
    "pytorch_net = create_pytorch_net(data.shape[1] - 1, NEURONS)\n",
    "pytorch_net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1: \n",
      "loss: 0.095232, mae:  0.1556\n",
      "Epoch2: \n",
      "loss: 0.083598, mae:  0.0991\n",
      "Epoch3: \n",
      "loss: 0.077849, mae:  0.0944\n",
      "Epoch4: \n",
      "loss: 0.077245, mae:  0.0915\n",
      "Epoch5: \n",
      "loss: 0.075610, mae:  0.0889\n",
      "Epoch6: \n",
      "loss: 0.075111, mae:  0.0873\n",
      "Epoch7: \n",
      "loss: 0.076353, mae:  0.0858\n",
      "Epoch8: \n",
      "loss: 0.073170, mae:  0.0850\n",
      "Epoch9: \n",
      "loss: 0.074998, mae:  0.0841\n",
      "Epoch10: \n",
      "loss: 0.072773, mae:  0.0838\n",
      "Epoch11: \n",
      "loss: 0.076641, mae:  0.0831\n",
      "Epoch12: \n",
      "loss: 0.071477, mae:  0.0828\n",
      "Epoch13: \n",
      "loss: 0.080216, mae:  0.0820\n",
      "Epoch14: \n",
      "loss: 0.074275, mae:  0.0823\n",
      "Epoch15: \n",
      "loss: 0.072062, mae:  0.0809\n",
      "Epoch16: \n",
      "loss: 0.070625, mae:  0.0814\n",
      "Epoch17: \n",
      "loss: 0.070001, mae:  0.0802\n",
      "Epoch18: \n",
      "loss: 0.071761, mae:  0.0799\n",
      "Epoch19: \n",
      "loss: 0.071344, mae:  0.0796\n",
      "Epoch20: \n",
      "loss: 0.071010, mae:  0.0795\n",
      "Epoch21: \n",
      "loss: 0.071006, mae:  0.0792\n",
      "Epoch22: \n",
      "loss: 0.070436, mae:  0.0790\n",
      "Epoch23: \n",
      "loss: 0.071310, mae:  0.0783\n",
      "Epoch24: \n",
      "loss: 0.069468, mae:  0.0781\n",
      "Epoch25: \n",
      "loss: 0.071608, mae:  0.0777\n",
      "Epoch26: \n",
      "loss: 0.070177, mae:  0.0776\n",
      "Epoch27: \n",
      "loss: 0.072600, mae:  0.0770\n",
      "Epoch28: \n",
      "loss: 0.068171, mae:  0.0770\n",
      "Epoch29: \n",
      "loss: 0.068022, mae:  0.0762\n",
      "Epoch30: \n",
      "loss: 0.067787, mae:  0.0764\n",
      "Epoch31: \n",
      "loss: 0.067615, mae:  0.0757\n",
      "Epoch32: \n",
      "loss: 0.065847, mae:  0.0754\n",
      "Epoch33: \n",
      "loss: 0.067921, mae:  0.0751\n",
      "Epoch34: \n",
      "loss: 0.067861, mae:  0.0740\n",
      "Epoch35: \n",
      "loss: 0.066503, mae:  0.0739\n",
      "Epoch36: \n",
      "loss: 0.067555, mae:  0.0742\n",
      "Epoch37: \n",
      "loss: 0.066829, mae:  0.0736\n",
      "Epoch38: \n",
      "loss: 0.067511, mae:  0.0730\n",
      "Epoch39: \n",
      "loss: 0.068045, mae:  0.0730\n",
      "Epoch40: \n",
      "loss: 0.068141, mae:  0.0727\n",
      "Epoch41: \n",
      "loss: 0.067723, mae:  0.0727\n",
      "Epoch42: \n",
      "loss: 0.066152, mae:  0.0722\n",
      "Epoch43: \n",
      "loss: 0.067622, mae:  0.0728\n",
      "Epoch44: \n",
      "loss: 0.067042, mae:  0.0717\n",
      "Epoch45: \n",
      "loss: 0.069655, mae:  0.0715\n",
      "Epoch46: \n",
      "loss: 0.067319, mae:  0.0713\n",
      "Epoch47: \n",
      "loss: 0.069425, mae:  0.0710\n",
      "Epoch48: \n",
      "loss: 0.068410, mae:  0.0713\n",
      "Epoch49: \n",
      "loss: 0.067939, mae:  0.0709\n",
      "Epoch50: \n",
      "loss: 0.067944, mae:  0.0716\n",
      "Epoch51: \n",
      "loss: 0.068750, mae:  0.0708\n",
      "Epoch52: \n",
      "loss: 0.069061, mae:  0.0706\n",
      "Epoch53: \n",
      "loss: 0.069374, mae:  0.0701\n",
      "Epoch54: \n",
      "loss: 0.069659, mae:  0.0705\n",
      "Epoch55: \n",
      "loss: 0.068041, mae:  0.0700\n",
      "Epoch56: \n",
      "loss: 0.068617, mae:  0.0699\n",
      "Epoch57: \n",
      "loss: 0.068543, mae:  0.0700\n",
      "Epoch58: \n",
      "loss: 0.068770, mae:  0.0703\n",
      "Epoch59: \n",
      "loss: 0.067923, mae:  0.0692\n",
      "Epoch60: \n",
      "loss: 0.069544, mae:  0.0699\n",
      "Epoch61: \n",
      "loss: 0.069145, mae:  0.0692\n",
      "Epoch62: \n",
      "loss: 0.067061, mae:  0.0689\n",
      "Epoch63: \n",
      "loss: 0.067838, mae:  0.0688\n",
      "Epoch64: \n",
      "loss: 0.070088, mae:  0.0693\n",
      "Epoch65: \n",
      "loss: 0.070176, mae:  0.0687\n",
      "Epoch66: \n",
      "loss: 0.066091, mae:  0.0682\n",
      "Epoch67: \n",
      "loss: 0.066322, mae:  0.0682\n",
      "Epoch68: \n",
      "loss: 0.067462, mae:  0.0684\n",
      "Epoch69: \n",
      "loss: 0.067311, mae:  0.0685\n",
      "Epoch70: \n",
      "loss: 0.068250, mae:  0.0681\n",
      "Epoch71: \n",
      "loss: 0.066334, mae:  0.0680\n",
      "Epoch72: \n",
      "loss: 0.066921, mae:  0.0678\n",
      "Epoch73: \n",
      "loss: 0.066453, mae:  0.0680\n",
      "Epoch74: \n",
      "loss: 0.067385, mae:  0.0682\n",
      "Epoch75: \n",
      "loss: 0.067089, mae:  0.0677\n",
      "Epoch76: \n",
      "loss: 0.066484, mae:  0.0676\n",
      "Epoch77: \n",
      "loss: 0.063806, mae:  0.0669\n",
      "Epoch78: \n",
      "loss: 0.064232, mae:  0.0673\n",
      "Epoch79: \n",
      "loss: 0.069728, mae:  0.0674\n",
      "Epoch80: \n",
      "loss: 0.065903, mae:  0.0670\n",
      "Epoch81: \n",
      "loss: 0.067089, mae:  0.0669\n",
      "Epoch82: \n",
      "loss: 0.063986, mae:  0.0672\n",
      "Epoch83: \n",
      "loss: 0.065513, mae:  0.0679\n",
      "Epoch84: \n",
      "loss: 0.065105, mae:  0.0670\n",
      "Epoch85: \n",
      "loss: 0.066090, mae:  0.0663\n",
      "Epoch86: \n",
      "loss: 0.066879, mae:  0.0659\n",
      "Epoch87: \n",
      "loss: 0.066035, mae:  0.0664\n",
      "Epoch88: \n",
      "loss: 0.064428, mae:  0.0662\n",
      "Epoch89: \n",
      "loss: 0.064597, mae:  0.0664\n",
      "Epoch90: \n",
      "loss: 0.065786, mae:  0.0661\n",
      "Epoch91: \n",
      "loss: 0.067180, mae:  0.0656\n",
      "Epoch92: \n",
      "loss: 0.065219, mae:  0.0662\n",
      "Epoch93: \n",
      "loss: 0.066148, mae:  0.0659\n",
      "Epoch94: \n",
      "loss: 0.066475, mae:  0.0656\n",
      "Epoch95: \n",
      "loss: 0.064177, mae:  0.0653\n",
      "Epoch96: \n",
      "loss: 0.065992, mae:  0.0655\n",
      "Epoch97: \n",
      "loss: 0.062073, mae:  0.0653\n",
      "Epoch98: \n",
      "loss: 0.065587, mae:  0.0656\n",
      "Epoch99: \n",
      "loss: 0.064517, mae:  0.0651\n",
      "Epoch100: \n",
      "loss: 0.064961, mae:  0.0651\n",
      "\n",
      "Training time:  45.6664 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(pytorch_net.parameters())\n",
    "pytorch_computation_time = 0\n",
    "for e in range(EPOCHS):\n",
    "    print(f\"Epoch{e+1}: \")\n",
    "    pytorch_computation_time += train_loop(train, pytorch_net, loss_function, optimizer)\n",
    "print(f\"\\nTraining time: {pytorch_computation_time: > 0.4f} seconds\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Error: loss:  0.086529, mae:  0.0865, rmse:  0.1335, R2:  0.6796\n"
     ]
    }
   ],
   "source": [
    "test_loop(test, pytorch_net, loss_function)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tensorflow\n",
    "TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}