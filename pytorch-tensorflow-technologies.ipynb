{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PhD course: a Comparative Introduction to Deep Learning Frameworks: TensorFlow, PyTorch and JAX - Coursework\n",
    "@author Matteo Magnini, Ph.D. student of the Computer Science and Engineering (38th cycle) course of the University of Bologna.\n",
    "\n",
    "This notebook presents a comparison study between `PyTorch` and `Tensorflow` (`Keras`).\n",
    "Given a public dataset, the same ML model -- a deep neural network -- is built, trained and tested with both technologies.\n",
    "Moreover, the two models are also evaluated on the computational time during training.\n",
    "\n",
    "Note: the experiments are reproducible via explicit seed declaration (just change it if you want to see different executions).\n",
    "Obviously, execution time is hardware and OS dependent, so time evaluation may differ.\n",
    "Output cells of this notebook have been computed on a Mac (Ventura 13) M1 with 16 GB of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some necessary imports."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from torch import nn, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras import Input, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.framework.random_seed import set_random_seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyper-parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATASET_URL = 'http://lib.stat.cmu.edu/datasets/houses.zip'\n",
    "\n",
    "SEED = 1\n",
    "TRAIN_RATIO = 2 / 3\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "NEURONS_PER_LAYER = [128, 128, 64, 64, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)\n",
    "\n",
    "\n",
    "def create_pytorch_net(input_shape, neurons):\n",
    "    linear_layers = [nn.Linear(neurons[i], neurons[i + 1])for i in range(len(neurons) - 1)]\n",
    "    relu_layers = (len(neurons) - 1) * [nn.ReLU()]\n",
    "    mixed_layers = [None]*(len(linear_layers)+len(relu_layers))\n",
    "    mixed_layers[::2] = relu_layers\n",
    "    mixed_layers[1::2] = linear_layers\n",
    "    return nn.Sequential(nn.Linear(input_shape, neurons[0]), *mixed_layers)\n",
    "\n",
    "\n",
    "def create_tensorflow_net(input_shape, neurons):\n",
    "    net_input = Input(input_shape)\n",
    "    x = Dense(neurons[0], activation=\"relu\")(net_input)\n",
    "    for neuron in neurons[1:-1]:\n",
    "        x = Dense(neuron, activation=\"relu\")(x)\n",
    "    x = Dense(neurons[-1], activation=\"linear\")(x)\n",
    "    return Model(net_input, x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset\n",
    "The dataset I use for this coursework contains the housing prices of California in 1990.\n",
    "It is public available at `http://lib.stat.cmu.edu/datasets/houses.zip`.\n",
    "You must have internet connection in order to load the data.\n",
    "\n",
    "A brief description from authors:\n",
    "> We collected information on the variables using all the block groups in California from the 1990 Census.\n",
    "In this sample a block group on average includes 1425.5 individuals living in a geographically compact area.\n",
    "Naturally, the geographical area included varies inversely with the population density.\n",
    "We computed distances among the centroids of each block group as measured in latitude and longitude.\n",
    "We excluded all the block groups reporting zero entries for the independent and dependent variables.\n",
    "The final data contained 20,640 observations on 9 variables.\n",
    "The dependent variable is ln(median house value).\n",
    "\n",
    "The dataset consists of 8 independent variables and 1 dependent variable (median house value).\n",
    "The dataset contains 20,640 records.\n",
    "The task is to predict the house cost value from the independent variable (regression)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       median_house_value  median_income  housing_median_age         rooms  \\\ncount        20640.000000   20640.000000        20640.000000  20640.000000   \nmean        206855.816909       3.870671           28.639486   2635.763081   \nstd         115395.615874       1.899822           12.585558   2181.615252   \nmin          14999.000000       0.499900            1.000000      2.000000   \n25%         119600.000000       2.563400           18.000000   1447.750000   \n50%         179700.000000       3.534800           29.000000   2127.000000   \n75%         264725.000000       4.743250           37.000000   3148.000000   \nmax         500001.000000      15.000100           52.000000  39320.000000   \n\n           bedrooms    population    households      latitude     longitude  \ncount  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000  \nmean     537.898014   1425.476744    499.539680     35.631861   -119.569704  \nstd      421.247906   1132.462122    382.329753      2.135952      2.003532  \nmin        1.000000      3.000000      1.000000     32.540000   -124.350000  \n25%      295.000000    787.000000    280.000000     33.930000   -121.800000  \n50%      435.000000   1166.000000    409.000000     34.260000   -118.490000  \n75%      647.000000   1725.000000    605.000000     37.710000   -118.010000  \nmax     6445.000000  35682.000000   6082.000000     41.950000   -114.310000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>median_house_value</th>\n      <th>median_income</th>\n      <th>housing_median_age</th>\n      <th>rooms</th>\n      <th>bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>latitude</th>\n      <th>longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>206855.816909</td>\n      <td>3.870671</td>\n      <td>28.639486</td>\n      <td>2635.763081</td>\n      <td>537.898014</td>\n      <td>1425.476744</td>\n      <td>499.539680</td>\n      <td>35.631861</td>\n      <td>-119.569704</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>115395.615874</td>\n      <td>1.899822</td>\n      <td>12.585558</td>\n      <td>2181.615252</td>\n      <td>421.247906</td>\n      <td>1132.462122</td>\n      <td>382.329753</td>\n      <td>2.135952</td>\n      <td>2.003532</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>14999.000000</td>\n      <td>0.499900</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>32.540000</td>\n      <td>-124.350000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>119600.000000</td>\n      <td>2.563400</td>\n      <td>18.000000</td>\n      <td>1447.750000</td>\n      <td>295.000000</td>\n      <td>787.000000</td>\n      <td>280.000000</td>\n      <td>33.930000</td>\n      <td>-121.800000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>179700.000000</td>\n      <td>3.534800</td>\n      <td>29.000000</td>\n      <td>2127.000000</td>\n      <td>435.000000</td>\n      <td>1166.000000</td>\n      <td>409.000000</td>\n      <td>34.260000</td>\n      <td>-118.490000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>264725.000000</td>\n      <td>4.743250</td>\n      <td>37.000000</td>\n      <td>3148.000000</td>\n      <td>647.000000</td>\n      <td>1725.000000</td>\n      <td>605.000000</td>\n      <td>37.710000</td>\n      <td>-118.010000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>500001.000000</td>\n      <td>15.000100</td>\n      <td>52.000000</td>\n      <td>39320.000000</td>\n      <td>6445.000000</td>\n      <td>35682.000000</td>\n      <td>6082.000000</td>\n      <td>41.950000</td>\n      <td>-114.310000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATASET_URL, sep=\"\\s+\", skiprows=27, header=None, encoding='windows-1252')\n",
    "data.columns = [\"median_house_value\", \"median_income\", \"housing_median_age\", \"rooms\", \"bedrooms\", \"population\", \"households\", \"latitude\", \"longitude\"]\n",
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split into train and test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       median_house_value  median_income  housing_median_age   rooms  \\\n16054            336100.0         4.4094                52.0  3260.0   \n20161            161200.0         2.5441                41.0  1408.0   \n6525             176100.0         3.2132                39.0  1258.0   \n15763            412500.0         2.3977                52.0  2514.0   \n19798             61500.0         1.8696                23.0  1091.0   \n...                   ...            ...                 ...     ...   \n10955            205300.0         1.7823                17.0  1768.0   \n17289            500001.0         8.5608                42.0  1765.0   \n5192             104800.0         1.1326                42.0  1433.0   \n12172            140700.0         2.6322                10.0  2381.0   \n235              126000.0         2.3036                35.0  1802.0   \n\n       bedrooms  population  households  latitude  longitude  \n16054     653.0      1594.0       632.0     37.76    -122.48  \n20161     311.0       793.0       264.0     34.37    -119.29  \n6525      245.0       988.0       228.0     34.06    -118.04  \n15763     729.0      1428.0       597.0     37.77    -122.43  \n19798     217.0       539.0       201.0     40.54    -123.12  \n...         ...         ...         ...       ...        ...  \n10955     474.0      1079.0       436.0     33.76    -117.88  \n17289     263.0       753.0       260.0     34.42    -119.63  \n5192      295.0       775.0       293.0     33.93    -118.26  \n12172     454.0      1323.0       477.0     33.73    -117.16  \n235       459.0      1009.0       390.0     37.79    -122.20  \n\n[13760 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>median_house_value</th>\n      <th>median_income</th>\n      <th>housing_median_age</th>\n      <th>rooms</th>\n      <th>bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>latitude</th>\n      <th>longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16054</th>\n      <td>336100.0</td>\n      <td>4.4094</td>\n      <td>52.0</td>\n      <td>3260.0</td>\n      <td>653.0</td>\n      <td>1594.0</td>\n      <td>632.0</td>\n      <td>37.76</td>\n      <td>-122.48</td>\n    </tr>\n    <tr>\n      <th>20161</th>\n      <td>161200.0</td>\n      <td>2.5441</td>\n      <td>41.0</td>\n      <td>1408.0</td>\n      <td>311.0</td>\n      <td>793.0</td>\n      <td>264.0</td>\n      <td>34.37</td>\n      <td>-119.29</td>\n    </tr>\n    <tr>\n      <th>6525</th>\n      <td>176100.0</td>\n      <td>3.2132</td>\n      <td>39.0</td>\n      <td>1258.0</td>\n      <td>245.0</td>\n      <td>988.0</td>\n      <td>228.0</td>\n      <td>34.06</td>\n      <td>-118.04</td>\n    </tr>\n    <tr>\n      <th>15763</th>\n      <td>412500.0</td>\n      <td>2.3977</td>\n      <td>52.0</td>\n      <td>2514.0</td>\n      <td>729.0</td>\n      <td>1428.0</td>\n      <td>597.0</td>\n      <td>37.77</td>\n      <td>-122.43</td>\n    </tr>\n    <tr>\n      <th>19798</th>\n      <td>61500.0</td>\n      <td>1.8696</td>\n      <td>23.0</td>\n      <td>1091.0</td>\n      <td>217.0</td>\n      <td>539.0</td>\n      <td>201.0</td>\n      <td>40.54</td>\n      <td>-123.12</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10955</th>\n      <td>205300.0</td>\n      <td>1.7823</td>\n      <td>17.0</td>\n      <td>1768.0</td>\n      <td>474.0</td>\n      <td>1079.0</td>\n      <td>436.0</td>\n      <td>33.76</td>\n      <td>-117.88</td>\n    </tr>\n    <tr>\n      <th>17289</th>\n      <td>500001.0</td>\n      <td>8.5608</td>\n      <td>42.0</td>\n      <td>1765.0</td>\n      <td>263.0</td>\n      <td>753.0</td>\n      <td>260.0</td>\n      <td>34.42</td>\n      <td>-119.63</td>\n    </tr>\n    <tr>\n      <th>5192</th>\n      <td>104800.0</td>\n      <td>1.1326</td>\n      <td>42.0</td>\n      <td>1433.0</td>\n      <td>295.0</td>\n      <td>775.0</td>\n      <td>293.0</td>\n      <td>33.93</td>\n      <td>-118.26</td>\n    </tr>\n    <tr>\n      <th>12172</th>\n      <td>140700.0</td>\n      <td>2.6322</td>\n      <td>10.0</td>\n      <td>2381.0</td>\n      <td>454.0</td>\n      <td>1323.0</td>\n      <td>477.0</td>\n      <td>33.73</td>\n      <td>-117.16</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>126000.0</td>\n      <td>2.3036</td>\n      <td>35.0</td>\n      <td>1802.0</td>\n      <td>459.0</td>\n      <td>1009.0</td>\n      <td>390.0</td>\n      <td>37.79</td>\n      <td>-122.20</td>\n    </tr>\n  </tbody>\n</table>\n<p>13760 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(data, train_size=TRAIN_RATIO, random_state=SEED)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalization\n",
    "It is a sound practice when the distributions of the input features are different to make the network more robust."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       median_house_value  median_income  housing_median_age     rooms  \\\n16054            0.662061       0.269617            1.000000  0.082863   \n20161            0.301444       0.140977            0.784314  0.035760   \n6525             0.332166       0.187122            0.745098  0.031945   \n15763            0.819586       0.130881            1.000000  0.063889   \n19798            0.095878       0.094461            0.431373  0.027697   \n...                   ...            ...                 ...       ...   \n10955            0.392372       0.088440            0.313725  0.044916   \n17289            1.000000       0.555916            0.803922  0.044840   \n5192             0.185156       0.043634            0.803922  0.036396   \n12172            0.259176       0.147053            0.176471  0.060507   \n235              0.228867       0.124391            0.666667  0.045781   \n\n       bedrooms  population  households  latitude  longitude  \n16054  0.105009    0.044592    0.117790  0.554729   0.182182  \n20161  0.049928    0.022142    0.049095  0.194474   0.501502  \n6525   0.039298    0.027607    0.042374  0.161530   0.626627  \n15763  0.117249    0.039939    0.111256  0.555792   0.187187  \n19798  0.034788    0.015023    0.037334  0.850159   0.118118  \n...         ...         ...         ...       ...        ...  \n10955  0.076180    0.030158    0.081202  0.129649   0.642643  \n17289  0.042197    0.021021    0.048348  0.199787   0.467467  \n5192   0.047351    0.021637    0.054508  0.147715   0.604605  \n12172  0.072959    0.036997    0.088856  0.126461   0.714715  \n235    0.073764    0.028196    0.072615  0.557917   0.210210  \n\n[13760 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>median_house_value</th>\n      <th>median_income</th>\n      <th>housing_median_age</th>\n      <th>rooms</th>\n      <th>bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>latitude</th>\n      <th>longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16054</th>\n      <td>0.662061</td>\n      <td>0.269617</td>\n      <td>1.000000</td>\n      <td>0.082863</td>\n      <td>0.105009</td>\n      <td>0.044592</td>\n      <td>0.117790</td>\n      <td>0.554729</td>\n      <td>0.182182</td>\n    </tr>\n    <tr>\n      <th>20161</th>\n      <td>0.301444</td>\n      <td>0.140977</td>\n      <td>0.784314</td>\n      <td>0.035760</td>\n      <td>0.049928</td>\n      <td>0.022142</td>\n      <td>0.049095</td>\n      <td>0.194474</td>\n      <td>0.501502</td>\n    </tr>\n    <tr>\n      <th>6525</th>\n      <td>0.332166</td>\n      <td>0.187122</td>\n      <td>0.745098</td>\n      <td>0.031945</td>\n      <td>0.039298</td>\n      <td>0.027607</td>\n      <td>0.042374</td>\n      <td>0.161530</td>\n      <td>0.626627</td>\n    </tr>\n    <tr>\n      <th>15763</th>\n      <td>0.819586</td>\n      <td>0.130881</td>\n      <td>1.000000</td>\n      <td>0.063889</td>\n      <td>0.117249</td>\n      <td>0.039939</td>\n      <td>0.111256</td>\n      <td>0.555792</td>\n      <td>0.187187</td>\n    </tr>\n    <tr>\n      <th>19798</th>\n      <td>0.095878</td>\n      <td>0.094461</td>\n      <td>0.431373</td>\n      <td>0.027697</td>\n      <td>0.034788</td>\n      <td>0.015023</td>\n      <td>0.037334</td>\n      <td>0.850159</td>\n      <td>0.118118</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10955</th>\n      <td>0.392372</td>\n      <td>0.088440</td>\n      <td>0.313725</td>\n      <td>0.044916</td>\n      <td>0.076180</td>\n      <td>0.030158</td>\n      <td>0.081202</td>\n      <td>0.129649</td>\n      <td>0.642643</td>\n    </tr>\n    <tr>\n      <th>17289</th>\n      <td>1.000000</td>\n      <td>0.555916</td>\n      <td>0.803922</td>\n      <td>0.044840</td>\n      <td>0.042197</td>\n      <td>0.021021</td>\n      <td>0.048348</td>\n      <td>0.199787</td>\n      <td>0.467467</td>\n    </tr>\n    <tr>\n      <th>5192</th>\n      <td>0.185156</td>\n      <td>0.043634</td>\n      <td>0.803922</td>\n      <td>0.036396</td>\n      <td>0.047351</td>\n      <td>0.021637</td>\n      <td>0.054508</td>\n      <td>0.147715</td>\n      <td>0.604605</td>\n    </tr>\n    <tr>\n      <th>12172</th>\n      <td>0.259176</td>\n      <td>0.147053</td>\n      <td>0.176471</td>\n      <td>0.060507</td>\n      <td>0.072959</td>\n      <td>0.036997</td>\n      <td>0.088856</td>\n      <td>0.126461</td>\n      <td>0.714715</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>0.228867</td>\n      <td>0.124391</td>\n      <td>0.666667</td>\n      <td>0.045781</td>\n      <td>0.073764</td>\n      <td>0.028196</td>\n      <td>0.072615</td>\n      <td>0.557917</td>\n      <td>0.210210</td>\n    </tr>\n  </tbody>\n</table>\n<p>13760 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_n, test_n = (train-train.min())/(train.max()-train.min()), (test-test.min())/(test.max()-test.min())\n",
    "train_n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PyTorch\n",
    "Dataframes are converted into pytorch tensors and then a `DataLoader` is created for both train and test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_pt = DataLoader(df_to_tensor(train_n), batch_size=BATCH_SIZE)\n",
    "test_pt = DataLoader(df_to_tensor(test_n), batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definition of train and test loop functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train_loop(train_loader, model, loss_fn, opt, verbose=False):\n",
    "    \"\"\"\n",
    "    :param train_loader: pytorch loader for the training sry\n",
    "    :param model: the neural network\n",
    "    :param loss_fn: the loss function\n",
    "    :param opt: the optimizer\n",
    "    :param verbose: print loss if true\n",
    "    :return: the execution time (prints are excluded but the computation of the loss function is included)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    num_batches = len(train_loader)\n",
    "    train_loss = 0\n",
    "    for batch, train_batch in enumerate(train_loader):\n",
    "        train_x, train_y = train_batch[:, 1:], train_batch[:, :1]\n",
    "        pred_y = model(train_x)\n",
    "        loss = loss_fn(pred_y, train_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        train_loss /= num_batches\n",
    "        opt.step()\n",
    "    loss, current = loss.item(), batch * len(train_x)\n",
    "    execution_time = time.time() - start_time\n",
    "    if verbose:\n",
    "        print(f\"loss: {loss:>4f}\")\n",
    "    return execution_time\n",
    "\n",
    "\n",
    "def test_loop(test_loader, model, loss_fn):\n",
    "    num_batches = len(test_loader)\n",
    "    num_records = sum([batch.shape[0] for batch in test_loader])\n",
    "    test_loss, mae, ssr, sst = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for test_batch in test_loader:\n",
    "            test_x, test_y = test_batch[:, 1:], test_batch[:, :1]\n",
    "            pred_y = model(test_x)\n",
    "            test_loss += loss_fn(pred_y, test_y).item() / num_batches\n",
    "            mae += sum(abs(test_y - pred_y))\n",
    "            ssr += sum((test_y - pred_y) ** 2)\n",
    "            sst += sum((test_y - test_loader.dataset[:, 0].mean()) ** 2)\n",
    "            r2 = (1 - ssr / sst).item()\n",
    "    rmse = (ssr / num_records) ** (1/2)\n",
    "    mae /= num_records\n",
    "    print(f\"\\nTest Error:\\n loss: {test_loss: > 0.4f}, mae: {mae.item(): > 0.4f}, rmse: {rmse.item(): > 0.4f}, R2: {r2: > 0.4f}\")\n",
    "    return test_loss, mae.item(), rmse.item(), r2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construction of the neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Linear(in_features=8, out_features=128, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=128, out_features=128, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=128, out_features=64, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=64, out_features=64, bias=True)\n  (7): ReLU()\n  (8): Linear(in_features=64, out_features=1, bias=True)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_seed(SEED)\n",
    "pytorch_net = create_pytorch_net(data.shape[1] - 1, NEURONS_PER_LAYER)\n",
    "pytorch_net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch10: \n",
      "loss: 0.075344\n",
      "Epoch20: \n",
      "loss: 0.070337\n",
      "Epoch30: \n",
      "loss: 0.069621\n",
      "Epoch40: \n",
      "loss: 0.065950\n",
      "Epoch50: \n",
      "loss: 0.067749\n",
      "Epoch60: \n",
      "loss: 0.063570\n",
      "Epoch70: \n",
      "loss: 0.062044\n",
      "Epoch80: \n",
      "loss: 0.061082\n",
      "Epoch90: \n",
      "loss: 0.061750\n",
      "Epoch100: \n",
      "loss: 0.061919\n",
      "\n",
      "Training time:  10.2276 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(pytorch_net.parameters())\n",
    "pytorch_computation_time = 0\n",
    "for e in range(EPOCHS):\n",
    "    if e%10 == 9:\n",
    "        print(f\"Epoch{e+1}: \")\n",
    "    pytorch_computation_time += train_loop(train_pt, pytorch_net, loss_function, optimizer, e%10 == 9)\n",
    "print(f\"\\nTraining time: {pytorch_computation_time: > 0.4f} seconds\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing\n",
    "Note that the loss function is the mean absolute error so the two values should be equals."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Error:\n",
      " loss:  0.0839, mae:  0.0838, rmse:  0.1310, R2:  0.6914\n"
     ]
    }
   ],
   "source": [
    "pytorch_loss, pytorch_mae, pytorch_rmse, pytorch_r2 = test_loop(test_pt, pytorch_net, loss_function)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_x, train_y = train_n.iloc[:, 1:], train_n.iloc[:, :1]\n",
    "test_x, test_y = test_n.iloc[:, 1:], test_n.iloc[:, :1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construction of the neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 30,145\n",
      "Trainable params: 30,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(SEED)\n",
    "tensorflow_net = create_tensorflow_net(test_x.shape[1], NEURONS_PER_LAYER)\n",
    "tensorflow_net.compile(optimizer=\"adam\", loss=\"mean_absolute_error\", metrics=\"mean_absolute_error\")\n",
    "tensorflow_net.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training\n",
    "Verbose level is 0 to avoid prints during the training.\n",
    "In this way the time evaluation should be fair with respect to pytorch network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 16:07:46.545285: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time:  13.6556 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensorflow_computation_time = time.time()\n",
    "tensorflow_net.fit(train_x, train_y, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0)\n",
    "tensorflow_computation_time = time.time() - tensorflow_computation_time\n",
    "print(f\"\\nTraining time: {tensorflow_computation_time: > 0.4f} seconds\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "R2 and rmse functions definition for testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def r2(y_true, y_pred):\n",
    "  residual = tf.reduce_sum(tf.square(tf.subtract(y_true, y_pred)))\n",
    "  total = tf.reduce_sum(tf.square(tf.subtract(y_true, tf.reduce_mean(y_true))))\n",
    "  return tf.subtract(1.0, tf.divide(residual, total))\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean((y_true - y_pred)**2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 0s 353us/step - loss: 0.0831 - mean_absolute_error: 0.0831 - rmse: 0.1286 - r2: 0.6694\n",
      "\n",
      "Test Error:\n",
      " loss:  0.0831, mae:  0.0831, rmse:  0.1286, R2:  0.6694\n"
     ]
    }
   ],
   "source": [
    "tensorflow_net.compile(optimizer=\"adam\", loss=\"mean_absolute_error\", metrics=[\"mean_absolute_error\", rmse, r2])\n",
    "tf_loss, tf_mae, tf_rmse, tf_r2 = tensorflow_net.evaluate(test_x, test_y)\n",
    "print(f\"\\nTest Error:\\n loss: {tf_loss: > 0.4f}, mae: {tf_mae: > 0.4f}, rmse: {tf_rmse: > 0.4f}, R2: {tf_r2: > 0.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Frameworks comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                  loss  mean_absolute_error  root_mean_squared_error        r2\npytorch       0.083851             0.083832                 0.131049  0.691383\ntensorflow    0.083054             0.083054                 0.128554  0.669389\npt - tf       0.000797             0.000778                 0.002495  0.021994\n% pt over tf  0.959625             0.937269                 1.940798  3.285655",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>mean_absolute_error</th>\n      <th>root_mean_squared_error</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>pytorch</th>\n      <td>0.083851</td>\n      <td>0.083832</td>\n      <td>0.131049</td>\n      <td>0.691383</td>\n    </tr>\n    <tr>\n      <th>tensorflow</th>\n      <td>0.083054</td>\n      <td>0.083054</td>\n      <td>0.128554</td>\n      <td>0.669389</td>\n    </tr>\n    <tr>\n      <th>pt - tf</th>\n      <td>0.000797</td>\n      <td>0.000778</td>\n      <td>0.002495</td>\n      <td>0.021994</td>\n    </tr>\n    <tr>\n      <th>% pt over tf</th>\n      <td>0.959625</td>\n      <td>0.937269</td>\n      <td>1.940798</td>\n      <td>3.285655</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame([[pytorch_loss, pytorch_mae, pytorch_rmse, pytorch_r2],\n",
    "                           [tf_loss, tf_mae, tf_rmse, tf_r2],\n",
    "                           [pytorch_loss - tf_loss, pytorch_mae - tf_mae, pytorch_rmse - tf_rmse, pytorch_r2 - tf_r2],\n",
    "                           [(pytorch_loss/tf_loss - 1) * 100, (pytorch_mae/tf_mae - 1) * 100, (pytorch_rmse/tf_rmse - 1) * 100 , (pytorch_r2/tf_r2 - 1) * 100]])\n",
    "comparison.columns = [\"loss\", \"mean_absolute_error\", \"root_mean_squared_error\", \"r2\"]\n",
    "comparison.index = [\"pytorch\", \"tensorflow\", \"pt - tf\", \"% pt over tf\"]\n",
    "comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Execution time comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time absolute difference (pt time - tf time): -3.4280 seconds\n",
      "\n",
      "\n",
      "Training time relative difference (pt time over tf time): -25.10 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTraining time absolute difference (pt time - tf time): {pytorch_computation_time - tensorflow_computation_time: > 0.4f} seconds\\n\")\n",
    "print(f\"\\nTraining time relative difference (pt time over tf time): {(pytorch_computation_time/tensorflow_computation_time - 1) * 100: > 0.2f} %\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Metrics concerning the networks' inference ability -- loss, mae, rsme, r2 -- are much similar to each others.\n",
    "This is a quite expected result because, despite the different frameworks, the undergoing network structure is exactly the same for both experiments.\n",
    "Moreover, the hyper-parameters are the same, so there is no surprise here.\n",
    "\n",
    "Instead, the execution time (at least for this particular dataset on this machine) is different.\n",
    "Indeed `PyTorch` looks to be significantly faster --- by 25-30% --- than `Tensorflow` (`Keras`).\n",
    "Obviously this means little, on a standard `CoLab` instance the percentage is similar but in favour of `Tensorflow` (the other metrics remain similar)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}